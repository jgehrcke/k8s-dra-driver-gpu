/*
 * SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package main

import (
	"fmt"

	"github.com/Masterminds/semver"
	resourceapi "k8s.io/api/resource/v1"
	"k8s.io/apimachinery/pkg/api/resource"
	"k8s.io/apimachinery/pkg/api/validate/constraints"
	"k8s.io/dynamic-resource-allocation/deviceattribute"
	"k8s.io/utils/ptr"
)

type PartCapacityMap map[resourceapi.QualifiedName]resourceapi.DeviceCapacity

// KEP 4815 device announcement: return device attributes for a partition that
// represents the full, regular GPU.
func (d *GpuInfo) PartDevAttributes() map[resourceapi.QualifiedName]resourceapi.DeviceAttribute {
	// TODO: Consume GetPCIBusIDAttribute from https://github.com/kubernetes/kubernetes/blob/4c5746c0bc529439f78af458f8131b5def4dbe5d/staging/src/k8s.io/dynamic-resource-allocation/deviceattribute/attribute.go#L39
	pciBusIDAttrName := resourceapi.QualifiedName(deviceattribute.StandardDeviceAttributePrefix + "pciBusID")
	return map[resourceapi.QualifiedName]resourceapi.DeviceAttribute{
		"type": {
			StringValue: ptr.To(GpuDeviceType),
		},
		"uuid": {
			StringValue: &d.UUID,
		},
		"productName": {
			StringValue: &d.productName,
		},
		"brand": {
			StringValue: &d.brand,
		},
		"architecture": {
			StringValue: &d.architecture,
		},
		"cudaComputeCapability": {
			VersionValue: ptr.To(semver.MustParse(d.cudaComputeCapability).String()),
		},
		"driverVersion": {
			VersionValue: ptr.To(semver.MustParse(d.driverVersion).String()),
		},
		"cudaDriverVersion": {
			VersionValue: ptr.To(semver.MustParse(d.cudaDriverVersion).String()),
		},
		pciBusIDAttrName: {
			StringValue: &d.pcieBusID,
		},
	}
}

// KEP 4815 device announcement: return the full device capacity for this device
// (uses information from looking at all MIG profiles beforehand).
func (d *GpuInfo) PartCapacities() PartCapacityMap {
	return d.maxCapacities
}

// KEP 4815 device announcement: return the name for the shared counter
// representing this full device.
func (d *GpuInfo) GetSharedCounterSetName() string {
	return toRFC1123Compliant(fmt.Sprintf("%s-counter-set", d.CanonicalName()))
}

// KEP 4815 device announcement: for now, define exactly one CounterSet per full
// GPU device. Individual partitions consume from that. In that CounterSet,
// define one counter per device capacity dimension, and add one counter
// (capacity 1) per memory slice.
func (d *GpuInfo) PartSharedCounterSets() []resourceapi.CounterSet {
	return []resourceapi.CounterSet{{
		Name:     d.GetSharedCounterSetName(),
		Counters: addCountersForMemSlices(capacitiesToCounters(d.maxCapacities), 0, d.memSliceCount),
	}}
}

// KEP 4815 device announcement: define what this full GPU consumes when allocated.
// Let the full device consume everything. Goals: 1) when the full device is
// allocated, all available counters drop to zero. 2) when the smallest
// partition gets allocated, the full device cannot be allocated anymore.
func (d *GpuInfo) PartConsumesCounters() []resourceapi.DeviceCounterConsumption {
	return []resourceapi.DeviceCounterConsumption{{
		CounterSet: d.GetSharedCounterSetName(),
		Counters:   addCountersForMemSlices(capacitiesToCounters(d.maxCapacities), 0, d.memSliceCount),
	}}
}

// KEP 4815 device announcement: return the 'full' device description.
func (d *GpuInfo) PartGetDevice() resourceapi.Device {
	dev := resourceapi.Device{
		Name:             d.CanonicalName(),
		Attributes:       d.PartDevAttributes(),
		Capacity:         d.PartCapacities(),
		ConsumesCounters: d.PartConsumesCounters(),
	}

	// Not available in all environments, enrich advertised device only
	// conditionally.
	if d.pcieRootAttr != nil {
		dev.Attributes[d.pcieRootAttr.Name] = d.pcieRootAttr.Value
	}

	return dev
}

// Return the full KEP 4815 representation of an abstract MIG device.
func (i *MigSpec) PartGetDevice() resourceapi.Device {
	d := resourceapi.Device{
		Name:             i.CanonicalName(),
		Attributes:       i.PartAttributes(),
		Capacity:         i.PartCapacities(),
		ConsumesCounters: i.PartConsumesCounters(),
	}
	return d
}

// Return the KEP 4818 capacities of an abstract MIG device.
//
// TODOMIG(JP): announce memory slices as capacities or not?
//
// Note(JP): for now, I feel like we may want to decouple capacity from
// placement. That would imply not announcing specific memory slices as part of
// capacity (specific memory slices encode placement). That makes sense to me,
// but I may of course miss something here.
//
// I noticed that in an example spec in KEP 4815 we enumerate memory slices in a
// partition's capacity. Example:
//
//   - name: gpu-2-mig-1g24gb-19-0
//     attributes:
//     ...
//     capacity:
//     ...
//     decoders:
//     value: "1"
//     encoders:
//     value: "0"
//     ...
//     memorySlice0:
//     value: "1"
//     memorySlice1:
//     value: "1"
//     multiprocessors:
//     value: "28"
//     ...
//
// 1) There, we only announce those slices with value 1 but we do _not_ announce
// memory slices not consumed (value: 0). That's inconsistent with other
// capacity dimensions which (in the example above) are enumerated despite
// having a value of zero (e.g. `encoders` above).
//
// 2) Semantically, to me, capacity I think can (and should?) be independent of
// placement. I am happy to be convinced otherwise.
//
// 3) If `capacityâ€œ is in our case always encoding the _same_ information as
// `consumesCounters` then that is a lot of duplication and feels a bit wrong.
// They serve a different need, and hence there may be differences.
func (i MigSpec) PartCapacities() PartCapacityMap {
	p := i.GIProfileInfo
	return PartCapacityMap{
		"multiprocessors": intcap(p.MultiprocessorCount),
		"copyEngines":     intcap(p.CopyEngineCount),
		"decoders":        intcap(p.DecoderCount),
		"encoders":        intcap(p.EncoderCount),
		"jpegEngines":     intcap(p.JpegCount),
		"ofaEngines":      intcap(p.OfaCount),
		// In the k8s world, we love announcing unit-less memory :-). `memory`
		// here is announced implicitly with the unit "Bytes". The MIG profile's
		// MemorySizeMB` property comes straight from NVML and is documented in
		// the public API docs with "Memory size in MBytes". As it says "MB" and
		// not MiB", one could assume that unit to be 10^6 Bytes. However, in
		// nvml.h this type's property is documented with `memorySizeMB; //!<
		// Device memory size (in MiB)`. Hence, the unit is 2^20 Bytes (1024 *
		// 1024 Bytes).
		"memory": intcap(int64(p.MemorySizeMB * 1024 * 1024)),
	}
}

func (i MigSpec) PartAttributes() map[resourceapi.QualifiedName]resourceapi.DeviceAttribute {
	// TODO: Consume GetPCIBusIDAttribute from https://github.com/kubernetes/kubernetes/blob/4c5746c0bc529439f78af458f8131b5def4dbe5d/staging/src/k8s.io/dynamic-resource-allocation/deviceattribute/attribute.go#L39
	pciBusIDAttrName := resourceapi.QualifiedName(deviceattribute.StandardDeviceAttributePrefix + "pciBusID")
	return map[resourceapi.QualifiedName]resourceapi.DeviceAttribute{
		// TODOMIG:
		// - do not hard-code "mig"?
		// - expose parent index?
		// - really expose parent minor?
		"type": {
			StringValue: ptr.To("mig"),
		},
		"parentUUID": {
			StringValue: &i.Parent.UUID,
		},
		"parentMinor": {
			IntValue: ptr.To(int64(i.Parent.minor)),
		},
		"profile": {
			StringValue: ptr.To(i.Profile.String()),
		},
		"productName": {
			StringValue: &i.Parent.productName,
		},
		"brand": {
			StringValue: &i.Parent.brand,
		},
		"architecture": {
			StringValue: &i.Parent.architecture,
		},
		"cudaComputeCapability": {
			VersionValue: ptr.To(semver.MustParse(i.Parent.cudaComputeCapability).String()),
		},
		pciBusIDAttrName: {
			StringValue: &i.Parent.pcieBusID,
		},
	}
}

func capacitiesToCounters(m PartCapacityMap) map[string]resourceapi.Counter {
	counters := make(map[string]resourceapi.Counter)
	for name, cap := range m {
		// Automatically derive counter name from capacity to ensure consistency.
		counters[camelToDNSName(string(name))] = resourceapi.Counter{Value: cap.Value}
	}
	return counters
}

// Construct and return the KEP 4815 DeviceCounterConsumption representation of
// an abstract MIG device.
//
// This device is a partition of a physical GPU. The returned
// `DeviceCounterConsumption` object describes which aspects precisely this
// partition consumes of the the full device.
//
// Each entry in capacity is modeled as a counter (consuming from the parent
// device). In addition, this MIG device, if allocated, consumes at least one
// specific memory slice. Each memory slice is modeled with its own counter
// (capacity: 1). Note that for example on a B200 GPU, the `3g.90gb` device
// consumes 4 out of 8 memory slices in total, but only 3 out of seven SMs. That
// is, with two `3g.90gb` devices allocated all memory slices are consumed, and
// one SM -- while unallocated -- cannot be used anymore. The parent is a full
// GPU device.
//
// When this device is allocated, it consumes from the parent's CounterSet. The
// parent's counter set is referred to by name. Use a naming convention:
// currently, a full GPU has precisely one counter set associated with it, and
// its name has the form 'gpu-%d-counter-set' where the placeholder is the GPU
// minor.
func (i MigSpec) PartConsumesCounters() []resourceapi.DeviceCounterConsumption {
	return []resourceapi.DeviceCounterConsumption{{
		CounterSet: i.Parent.GetSharedCounterSetName(),
		Counters:   addCountersForMemSlices(capacitiesToCounters(i.PartCapacities()), int(i.Placement.Start), int(i.Placement.Size)),
	}}
}

// A variant of the legacy `GetDevice()`, for the Partitionable Devices paradigm.
func (d *AllocatableDevice) PartGetDevice() resourceapi.Device {
	switch d.Type() {
	case GpuDeviceType:
		return d.Gpu.PartGetDevice()
	case MigStaticDeviceType:
		panic("PartGetDevice() called for MigStaticDeviceType")
	case MigDynamicDeviceType:
		return d.MigDynamic.PartGetDevice()
	case VfioDeviceType:
		panic("not yet implemented")
	}
	panic("unexpected type for AllocatableDevice")
}

// Insert one counter for each memory slice consumed, as given by the `start`
// and `size` parameters (from a nvml.GpuInstancePlacement). Mutate the input
// map in place, and (also) return it.
func addCountersForMemSlices(counters map[string]resourceapi.Counter, start int, size int) map[string]resourceapi.Counter {
	for i := start; i < start+size; i++ {
		counters[memsliceCounterName(i)] = resourceapi.Counter{Value: *resource.NewQuantity(1, resource.BinarySI)}
	}
	return counters
}

// Return canonical name for memory slice (placement) `i` (a zero-based index).
// Note that this name must be used for memslice-N counters in a SharedCounters
// counter set, and for corresponding counters in a ConsumesCounters counter
// set. Counters (as opposed to capacities) are allowed to have hyphens in their
// name.
func memsliceCounterName(i int) string {
	return fmt.Sprintf("memory-slice-%d", i)
}

// Helper for creating an integer-based DeviceCapacity. Accept any integer type.
func intcap[T constraints.Integer](i T) resourceapi.DeviceCapacity {
	return resourceapi.DeviceCapacity{Value: *resource.NewQuantity(int64(i), resource.BinarySI)}
}
